{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f04048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando pacotes\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7e5705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de treino shape: (32561, 15)\n",
      "Dataset de teste shape: (16281, 15)\n"
     ]
    }
   ],
   "source": [
    "#Preparação dos dados\n",
    "\n",
    "#Labels das colunas\n",
    "CSV_HEADER = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"income_bracket\",\n",
    "]\n",
    "\n",
    "#Importe dados de treino\n",
    "# train_data_url = (\n",
    "#     \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "# )\n",
    "\n",
    "train_data_url = 'dados/train_data.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_data_url, header=None, names=CSV_HEADER)\n",
    "\n",
    "#Importe dados de teste\n",
    "# test_data_url = (\n",
    "#     \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\"\n",
    "# )\n",
    "\n",
    "test_data_url = 'dados/test_data.csv'\n",
    "\n",
    "test_data = pd.read_csv(test_data_url, header=None, names=CSV_HEADER)\n",
    "\n",
    "print(f\"Dataset de treino shape: {train_data.shape}\")\n",
    "print(f\"Dataset de teste shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383b5844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "        gender  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "      income_bracket  \n",
       "0              <=50K  \n",
       "1              <=50K  \n",
       "2              <=50K  \n",
       "3              <=50K  \n",
       "4              <=50K  \n",
       "...              ...  \n",
       "32556          <=50K  \n",
       "32557           >50K  \n",
       "32558          <=50K  \n",
       "32559          <=50K  \n",
       "32560           >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3feceed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo primeira observação, dados inválido\n",
    "test_data = test_data[1:]\n",
    "\n",
    "#Removendo ponto da coluna income_bracket\n",
    "train_data.income_bracket = train_data.income_bracket.apply(lambda x: x.replace(\".\", \"\"))\n",
    "\n",
    "test_data.income_bracket = train_data.income_bracket.apply(lambda x: x.replace(\".\", \"\"))\n",
    "\n",
    "#Gerando arquivo csv local\n",
    "\n",
    "train_data_file = \"dados/train_data.csv\"\n",
    "test_data_file = \"dados/test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False, header=False)\n",
    "test_data.to_csv(test_data_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee566350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de nome das variáveis numéricas\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"age\",\n",
    "    \"education_num\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10852180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workclass': [' ?',\n",
       "  ' Federal-gov',\n",
       "  ' Local-gov',\n",
       "  ' Never-worked',\n",
       "  ' Private',\n",
       "  ' Self-emp-inc',\n",
       "  ' Self-emp-not-inc',\n",
       "  ' State-gov',\n",
       "  ' Without-pay'],\n",
       " 'education': [' 10th',\n",
       "  ' 11th',\n",
       "  ' 12th',\n",
       "  ' 1st-4th',\n",
       "  ' 5th-6th',\n",
       "  ' 7th-8th',\n",
       "  ' 9th',\n",
       "  ' Assoc-acdm',\n",
       "  ' Assoc-voc',\n",
       "  ' Bachelors',\n",
       "  ' Doctorate',\n",
       "  ' HS-grad',\n",
       "  ' Masters',\n",
       "  ' Preschool',\n",
       "  ' Prof-school',\n",
       "  ' Some-college'],\n",
       " 'marital_status': [' Divorced',\n",
       "  ' Married-AF-spouse',\n",
       "  ' Married-civ-spouse',\n",
       "  ' Married-spouse-absent',\n",
       "  ' Never-married',\n",
       "  ' Separated',\n",
       "  ' Widowed'],\n",
       " 'occupation': [' ?',\n",
       "  ' Adm-clerical',\n",
       "  ' Armed-Forces',\n",
       "  ' Craft-repair',\n",
       "  ' Exec-managerial',\n",
       "  ' Farming-fishing',\n",
       "  ' Handlers-cleaners',\n",
       "  ' Machine-op-inspct',\n",
       "  ' Other-service',\n",
       "  ' Priv-house-serv',\n",
       "  ' Prof-specialty',\n",
       "  ' Protective-serv',\n",
       "  ' Sales',\n",
       "  ' Tech-support',\n",
       "  ' Transport-moving'],\n",
       " 'relationship': [' Husband',\n",
       "  ' Not-in-family',\n",
       "  ' Other-relative',\n",
       "  ' Own-child',\n",
       "  ' Unmarried',\n",
       "  ' Wife'],\n",
       " 'race': [' Amer-Indian-Eskimo',\n",
       "  ' Asian-Pac-Islander',\n",
       "  ' Black',\n",
       "  ' Other',\n",
       "  ' White'],\n",
       " 'gender': [' Female', ' Male'],\n",
       " 'native_country': [' ?',\n",
       "  ' Cambodia',\n",
       "  ' Canada',\n",
       "  ' China',\n",
       "  ' Columbia',\n",
       "  ' Cuba',\n",
       "  ' Dominican-Republic',\n",
       "  ' Ecuador',\n",
       "  ' El-Salvador',\n",
       "  ' England',\n",
       "  ' France',\n",
       "  ' Germany',\n",
       "  ' Greece',\n",
       "  ' Guatemala',\n",
       "  ' Haiti',\n",
       "  ' Holand-Netherlands',\n",
       "  ' Honduras',\n",
       "  ' Hong',\n",
       "  ' Hungary',\n",
       "  ' India',\n",
       "  ' Iran',\n",
       "  ' Ireland',\n",
       "  ' Italy',\n",
       "  ' Jamaica',\n",
       "  ' Japan',\n",
       "  ' Laos',\n",
       "  ' Mexico',\n",
       "  ' Nicaragua',\n",
       "  ' Outlying-US(Guam-USVI-etc)',\n",
       "  ' Peru',\n",
       "  ' Philippines',\n",
       "  ' Poland',\n",
       "  ' Portugal',\n",
       "  ' Puerto-Rico',\n",
       "  ' Scotland',\n",
       "  ' South',\n",
       "  ' Taiwan',\n",
       "  ' Thailand',\n",
       "  ' Trinadad&Tobago',\n",
       "  ' United-States',\n",
       "  ' Vietnam',\n",
       "  ' Yugoslavia']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dicionário das variáveis categóricas\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"workclass\": sorted(list(train_data[\"workclass\"].unique())),\n",
    "    \"education\": sorted(list(train_data[\"education\"].unique())),\n",
    "    \"marital_status\": sorted(list(train_data[\"marital_status\"].unique())),\n",
    "    \"occupation\": sorted(list(train_data[\"occupation\"].unique())),\n",
    "    \"relationship\": sorted(list(train_data[\"relationship\"].unique())),\n",
    "    \"race\": sorted(list(train_data[\"race\"].unique())),\n",
    "    \"gender\": sorted(list(train_data[\"gender\"].unique())),\n",
    "    \"native_country\": sorted(list(train_data[\"native_country\"].unique())),\n",
    "}\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a9bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas ignoradas no dataset\n",
    "\n",
    "IGNORE_COLUMN_NAMES = [\"fnlwgt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f169715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'gender',\n",
       " 'native_country']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de nome das variáveis categóricas\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6775af01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de todas as variáveis do dataset\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9486f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuindo valores default para as colunas\n",
    "\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES + IGNORE_COLUMN_NAMES else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54bfe8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo variável target\n",
    "TARGET_FEATURE_NAME = \"income_bracket\"\n",
    "\n",
    "# Lista de labes da variável target\n",
    "TARGET_LABELS = [\" <=50K\", \" >50K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f55fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar dataset\n",
    "\n",
    "#Converte string em númericos (0,1)\n",
    "target_label_lookup = StringLookup(\n",
    "    vocabulary=TARGET_LABELS, mask_token=None, num_oov_indices=0\n",
    ")\n",
    "\n",
    "\n",
    "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=False,\n",
    "        na_value=\"?\",\n",
    "        shuffle=shuffle,\n",
    "    ).map(lambda features, target: (features, target_label_lookup(target)))\n",
    "    \n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffaf3483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para converter os tipos de dados\n",
    "\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4efa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para codificar os dados de entrada\n",
    "\n",
    "def encode_inputs(inputs):\n",
    "    \n",
    "    #Cria lista vazia\n",
    "    encoded_features = []\n",
    "    \n",
    "    #Loop para converter valores strings em índices inteiros\n",
    "    for feature_name in inputs:\n",
    "        \n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            \n",
    "            #Coleta os valores\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            \n",
    "            #Cria objeto Lookup\n",
    "            lookup = StringLookup(\n",
    "                vocabulary=vocabulary, mask_token=None, num_oov_indices=0\n",
    "            )\n",
    "            \n",
    "            # Converte entradas strings em índices inteiros\n",
    "            value_index = lookup(inputs[feature_name])\n",
    "            embedding_dims = int(math.sqrt(lookup.vocabulary_size()))\n",
    "            \n",
    "            # Cria uma camada oculta com dimensão especificada\n",
    "            embedding = layers.Embedding(\n",
    "                input_dim=lookup.vocabulary_size(), output_dim=embedding_dims\n",
    "            )\n",
    "            \n",
    "            #Converte os valores dos indices para as camadas ocultas\n",
    "            encoded_feature = embedding(value_index)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Utilização dos valores númericos das variáveis\n",
    "            encoded_feature = inputs[feature_name]\n",
    "            if inputs[feature_name].shape[-1] is None:\n",
    "                encoded_feature = tf.expand_dims(encoded_feature, -1)\n",
    "                \n",
    "        \n",
    "        #Anexa os indices codificados\n",
    "        encoded_features.append(encoded_feature)\n",
    "    \n",
    "    #Cria as camadas concatenadas\n",
    "    encoded_features = layers.concatenate(encoded_features)\n",
    "    \n",
    "    return encoded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f954689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural decision tree\n",
    "\n",
    "class NeuralDecisionTree(keras.Model):\n",
    "    \n",
    "    def __init__(self, depth, num_features, used_features_rate, num_classes):\n",
    "        \n",
    "        super(NeuralDecisionTree, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.num_leaves = 2 ** depth\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Cria a máscara para a seleção das features aletoriamente\n",
    "        num_used_features = int(num_features * used_features_rate)\n",
    "        one_hot = np.eye(num_features)\n",
    "        sampled_feature_indicies = np.random.choice(\n",
    "            np.arange(num_features), num_used_features, replace=False\n",
    "        )\n",
    "        self.used_features_mask = one_hot[sampled_feature_indicies]\n",
    "\n",
    "        # Inicializa o peso das classes\n",
    "        self.pi = tf.Variable(\n",
    "            initial_value=tf.random_normal_initializer()(\n",
    "                shape=[self.num_leaves, self.num_classes]\n",
    "            ),\n",
    "            dtype=\"float32\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "        # Define a função de ativação\n",
    "        self.decision_fn = layers.Dense(\n",
    "            units=self.num_leaves, activation=\"sigmoid\", name=\"decision\"\n",
    "        )\n",
    "\n",
    "    def call(self, features):\n",
    "        batch_size = tf.shape(features)[0]\n",
    "\n",
    "        # Aplica a máscara das features ao dados de entrada\n",
    "        features = tf.matmul(\n",
    "            features, self.used_features_mask, transpose_b=True\n",
    "        )\n",
    "        \n",
    "        # Calcula as probabilidades\n",
    "        decisions = tf.expand_dims(\n",
    "            self.decision_fn(features), axis=2\n",
    "        )\n",
    "        \n",
    "        # Concatena as probabilidades de roteamento com seus complementos\n",
    "        decisions = layers.concatenate(\n",
    "            [decisions, 1 - decisions], axis=2\n",
    "        )\n",
    "\n",
    "        mu = tf.ones([batch_size, 1, 1])\n",
    "        \n",
    "        #Inicializa indices\n",
    "        begin_idx = 1\n",
    "        end_idx = 2\n",
    "        \n",
    "        # Cria a árvore de decisão\n",
    "        for level in range(self.depth):\n",
    "            mu = tf.reshape(mu, [batch_size, -1, 1])  # [batch_size, 2 ** level, 1]\n",
    "            mu = tf.tile(mu, (1, 1, 2))  # [batch_size, 2 ** level, 2]\n",
    "            level_decisions = decisions[\n",
    "                :, begin_idx:end_idx, :\n",
    "            ]  # [batch_size, 2 ** level, 2]\n",
    "            mu = mu * level_decisions  # [batch_size, 2**level, 2]\n",
    "            begin_idx = end_idx\n",
    "            end_idx = begin_idx + 2 ** (level + 1)\n",
    "\n",
    "        mu = tf.reshape(mu, [batch_size, self.num_leaves])  # [batch_size, num_leaves]\n",
    "        \n",
    "        probabilities = keras.activations.softmax(self.pi)  # [num_leaves, num_classes]\n",
    "        \n",
    "        outputs = tf.matmul(mu, probabilities)  # [batch_size, num_classes]\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30ab1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural decision forest\n",
    "\n",
    "# Modelo neural decision foresst consiste em um conjunto de árvores de decisão treinados simultaneamente.\n",
    "# A acurácia do modelo é a acurácia média de todas as árvores\n",
    "\n",
    "class NeuralDecisionForest(keras.Model):\n",
    "    \n",
    "    def __init__(self, num_trees, depth, num_features, used_features_rate, num_classes):\n",
    "        \n",
    "        super(NeuralDecisionForest, self).__init__()\n",
    "        self.ensemble = []\n",
    "        \n",
    "        # Inicializa o ensemble pela adição das instâncias NeuralDecisionTree\n",
    "        for _ in range(num_trees):\n",
    "            self.ensemble.append(\n",
    "                NeuralDecisionTree(depth, num_features, used_features_rate, num_classes)\n",
    "            )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # inicializa as saídas: a [batch_size, num_classes] matriz de zeros.\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        outputs = tf.zeros([batch_size, num_classes])\n",
    "\n",
    "        # Afrega a saída das árvores no ensemble.\n",
    "        for tree in self.ensemble:\n",
    "            outputs += tree(inputs)\n",
    "            \n",
    "        # Média da saída de todas as árvores\n",
    "        outputs /= len(self.ensemble)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a49d87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e avaliação do modelo\n",
    "\n",
    "#Parâmentros de treino\n",
    "learning_rate = 0.01\n",
    "batch_size = 265\n",
    "num_epochs = 50\n",
    "hidden_units = [64, 64]\n",
    "\n",
    "\n",
    "def run_train(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    print(\"Iniciando treinamento do modelo...\")\n",
    "    train_dataset = get_dataset_from_csv(\n",
    "        train_data_file, shuffle=True, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Treinamento do modelo finalizado\")\n",
    "\n",
    "    print(\"Avaliação do modelo nos dados de teste...\")\n",
    "    test_dataset = get_dataset_from_csv(test_data_file, batch_size=batch_size)\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset)\n",
    "    print(f\"Acurácia: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fd40d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento decision tree model\n",
    "\n",
    "# Parâmentros da árvore\n",
    "num_trees = 10\n",
    "depth = 5\n",
    "used_features_rate = 1.0\n",
    "num_classes = len(TARGET_LABELS)\n",
    "\n",
    "\n",
    "def create_tree_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    tree = NeuralDecisionTree(depth, num_features, used_features_rate, num_classes)\n",
    "\n",
    "    outputs = tree(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "100d02e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando treinamento do modelo...\n",
      "Epoch 1/50\n",
      "123/123 [==============================] - 3s 13ms/step - loss: 0.4483 - sparse_categorical_accuracy: 0.8254\n",
      "Epoch 2/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.3403 - sparse_categorical_accuracy: 0.8513\n",
      "Epoch 3/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3253 - sparse_categorical_accuracy: 0.8534\n",
      "Epoch 4/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.3189 - sparse_categorical_accuracy: 0.8548\n",
      "Epoch 5/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3150 - sparse_categorical_accuracy: 0.8552\n",
      "Epoch 6/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3123 - sparse_categorical_accuracy: 0.8571\n",
      "Epoch 7/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.3099 - sparse_categorical_accuracy: 0.8584\n",
      "Epoch 8/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3080 - sparse_categorical_accuracy: 0.8591\n",
      "Epoch 9/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3063 - sparse_categorical_accuracy: 0.8599\n",
      "Epoch 10/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3049 - sparse_categorical_accuracy: 0.8606\n",
      "Epoch 11/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.3036 - sparse_categorical_accuracy: 0.8620\n",
      "Epoch 12/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3025 - sparse_categorical_accuracy: 0.8617\n",
      "Epoch 13/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3014 - sparse_categorical_accuracy: 0.8620\n",
      "Epoch 14/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.3004 - sparse_categorical_accuracy: 0.8625\n",
      "Epoch 15/50\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.2995 - sparse_categorical_accuracy: 0.8630\n",
      "Epoch 16/50\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.2985 - sparse_categorical_accuracy: 0.8631\n",
      "Epoch 17/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2977 - sparse_categorical_accuracy: 0.8631\n",
      "Epoch 18/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2969 - sparse_categorical_accuracy: 0.8638\n",
      "Epoch 19/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2963 - sparse_categorical_accuracy: 0.8643\n",
      "Epoch 20/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2957 - sparse_categorical_accuracy: 0.8650\n",
      "Epoch 21/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2951 - sparse_categorical_accuracy: 0.8654\n",
      "Epoch 22/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2946 - sparse_categorical_accuracy: 0.8657\n",
      "Epoch 23/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2941 - sparse_categorical_accuracy: 0.8663\n",
      "Epoch 24/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2936 - sparse_categorical_accuracy: 0.8660\n",
      "Epoch 25/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2932 - sparse_categorical_accuracy: 0.8664\n",
      "Epoch 26/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2928 - sparse_categorical_accuracy: 0.8666\n",
      "Epoch 27/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2924 - sparse_categorical_accuracy: 0.8671\n",
      "Epoch 28/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2919 - sparse_categorical_accuracy: 0.8677\n",
      "Epoch 29/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2915 - sparse_categorical_accuracy: 0.8678\n",
      "Epoch 30/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2912 - sparse_categorical_accuracy: 0.8679\n",
      "Epoch 31/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2908 - sparse_categorical_accuracy: 0.8683\n",
      "Epoch 32/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2905 - sparse_categorical_accuracy: 0.8684\n",
      "Epoch 33/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2901 - sparse_categorical_accuracy: 0.8690\n",
      "Epoch 34/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2898 - sparse_categorical_accuracy: 0.8689\n",
      "Epoch 35/50\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.2895 - sparse_categorical_accuracy: 0.8690\n",
      "Epoch 36/50\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.2892 - sparse_categorical_accuracy: 0.8689\n",
      "Epoch 37/50\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.2889 - sparse_categorical_accuracy: 0.8687\n",
      "Epoch 38/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2887 - sparse_categorical_accuracy: 0.8686\n",
      "Epoch 39/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2884 - sparse_categorical_accuracy: 0.8688\n",
      "Epoch 40/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2882 - sparse_categorical_accuracy: 0.8686\n",
      "Epoch 41/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2879 - sparse_categorical_accuracy: 0.8690\n",
      "Epoch 42/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.8694\n",
      "Epoch 43/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2874 - sparse_categorical_accuracy: 0.8696\n",
      "Epoch 44/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2872 - sparse_categorical_accuracy: 0.8697\n",
      "Epoch 45/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2870 - sparse_categorical_accuracy: 0.8697\n",
      "Epoch 46/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2869 - sparse_categorical_accuracy: 0.8698\n",
      "Epoch 47/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2867 - sparse_categorical_accuracy: 0.8697\n",
      "Epoch 48/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2865 - sparse_categorical_accuracy: 0.8698\n",
      "Epoch 49/50\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2863 - sparse_categorical_accuracy: 0.8702\n",
      "Epoch 50/50\n",
      "123/123 [==============================] - 1s 12ms/step - loss: 0.2862 - sparse_categorical_accuracy: 0.8701\n",
      "Treinamento do modelo finalizado\n",
      "Avaliação do modelo nos dados de teste...\n",
      "62/62 [==============================] - 1s 5ms/step - loss: 1.1008 - sparse_categorical_accuracy: 0.6482\n",
      "Acurácia: 64.82%\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inicia treinamento\n",
    "tree_model = create_tree_model()\n",
    "run_train(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "378e23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento forest model\n",
    "\n",
    "num_trees = 25\n",
    "depth = 5\n",
    "used_features_rate = 0.5\n",
    "\n",
    "\n",
    "def create_forest_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "    num_features = features.shape[1]\n",
    "\n",
    "    forest_model = NeuralDecisionForest(\n",
    "        num_trees, depth, num_features, used_features_rate, num_classes\n",
    "    )\n",
    "\n",
    "    outputs = forest_model(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29575f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando treinamento do modelo...\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 3s 13ms/step - loss: 0.3052 - sparse_categorical_accuracy: 0.8615\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.3029 - sparse_categorical_accuracy: 0.8633\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.3017 - sparse_categorical_accuracy: 0.8630\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.3006 - sparse_categorical_accuracy: 0.8637\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2997 - sparse_categorical_accuracy: 0.8642\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.8646\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2981 - sparse_categorical_accuracy: 0.8647\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.2974 - sparse_categorical_accuracy: 0.8650\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2968 - sparse_categorical_accuracy: 0.8657\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 2s 12ms/step - loss: 0.2962 - sparse_categorical_accuracy: 0.8663\n",
      "Treinamento do modelo finalizado\n",
      "Avaliação do modelo nos dados de teste...\n",
      "62/62 [==============================] - 1s 5ms/step - loss: 1.0452 - sparse_categorical_accuracy: 0.6499\n",
      "Acurácia: 64.99%\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Inicia treinamento\n",
    "forest_model = create_forest_model()\n",
    "\n",
    "run_train(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875a7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
